{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indonesian-familiar",
   "metadata": {},
   "source": [
    "# Hotel Recognition to Combat Human Trafficking | Exploratory Data Analysis\n",
    "    2021-04-05\n",
    "    Edward Sims\n",
    "\n",
    "## Introduction\n",
    "Victims of human trafficking are often photographed in hotel rooms as in the below examples. Identifying these hotels is vital to these trafficking investigations but poses particular challenges due to low quality of images and uncommon camera angles.\n",
    "\n",
    "![Image from Kaggle competition page: https://www.kaggle.com/c/hotel-id-2021-fgvc8/overview/description](images/example_victim_images.png)\n",
    "\n",
    "Even without victims in the images, hotel identification in general is a challenging fine-grained visual recognition task with a huge number of classes and potentially high intraclass and low interclass variation. In order to support research into this challenging task and create image search tools for human trafficking investigators, we created the TraffickCam mobile application, which allows every day travelers to submit photos of their hotel room. Read more about [TraffickCam on TechCrunch](https://techcrunch.com/2016/06/25/traffickcam/).\n",
    "\n",
    "## Evaluation\n",
    "Submissions are evaluated according to the Mean Average Precision @ 5 (MAP@5):\n",
    "\n",
    "<img src=\"images/map5_formula.png\" alt=\"MAP@5 formula\" style=\"width: 300px;\"/>\n",
    "\n",
    "where ***U*** is the number of images, ***P(k)*** is the precision at cutoff ***k***, ***n*** is the number of predictions per image, and ***rel(k)*** is an indicator function equaling 1 if the item at rank ***k*** is a relevant correct label, zero otherwise.\n",
    "\n",
    "Once a correct label has been scored for an observation, that label is no longer considered relevant for that observation, and additional predictions of that label are skipped in the calculation. For example, if the correct label is ***A*** for an observation, the following predictions all score an average precision of 1.0.\n",
    "\n",
    "```\n",
    "A B C D E\n",
    "A A A A A\n",
    "A B A C A\n",
    "```\n",
    "\n",
    "## Submission File\n",
    "For each image in the test set, you must predict a space-delimited list of hotel IDs that could match that image. The list should be sorted such that the first ID is considered the most relevant one and the last the least relevant one. The file should contain a header and have the following format:\n",
    "\n",
    "```\n",
    "image,hotel_id \n",
    "99e91ad5f2870678.jpg,36363 53586 18807 64314 60181\n",
    "b5cc62ab665591a9.jpg,36363 53586 18807 64314 60181\n",
    "d5664a972d5a644b.jpg,36363 53586 18807 64314 60181\n",
    "```\n",
    "\n",
    "## Data \n",
    "Identifying the location of a hotel room is a challenging problem of great interest for combating human trafficking. This competition provides a rich dataset of photos of hotel room interiors, without any people present, for this purpose.\n",
    "\n",
    "Many of the hotels are independent or part of very small chains, where shared decor isn't a concern. However, the shared standards for their interior decoration for the larger chains means that many hotels can look quite similar at first glance. Identifying the chain can narrow the range of possibilities, but only down to a set that is much harder to tell apart and is still scattered across a wide geographic area. The real value lies in getting the number of candidates to a small enough number that a human investigator could follow up on all of them.\n",
    "\n",
    "### Files\n",
    "**train.csv** - The training set metadata.\n",
    " - `image` - The image ID.\n",
    " - `chain` - An ID code for the hotel chain. A chain of zero (0) indicates that the hotel is either not part of a chain or the chain is not known. This field is not available for the test set. The number of hotels per chain varies widely.\n",
    " - `hotel_id` - The hotel ID. The target class.\n",
    " - `timestamp` - When the image was taken. Provided for the training set only.\n",
    " \n",
    "**sample_submission.csv** - A sample submission file in the correct format.\n",
    " - `image` The image ID\n",
    " - `hotel_id` The hotel ID. The target class.\n",
    " \n",
    "**train_images** - The training set contains 97000+ images from around 7700 hotels from across the globe. All of the images for each hotel chain are in a dedicated subfolder for that chain.\n",
    "\n",
    "**test_images** - The test set images. This competition has a hidden test set: only three images are provided here as samples while the remaining 13,000 images will be available to your notebook once it is submitted.\n",
    "\n",
    "## 1.00 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accessible-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datetime import datetime as dt\n",
    "import cv2\n",
    "\n",
    "# General packages\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Data vis packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Package options\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "plt.rcParams[\"figure.figsize\"] = [14, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff28259",
   "metadata": {},
   "source": [
    "## 2.00 Read in data\n",
    "### 2.01 Get paths and set initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfca6cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "data_dir_path         = \"../input/hotel-id-2021-fgvc8\"\n",
    "train_images_dir_path = os.path.join(data_dir_path, \"train_images\")\n",
    "test_images_dir_path  = os.path.join(data_dir_path, \"test_images\")\n",
    "\n",
    "train_metadata_path   = os.path.join(data_dir_path, \"train.csv\")\n",
    "sample_sub_path       = os.path.join(data_dir_path, \"sample_submission.csv\")\n",
    "\n",
    "# Read csv data\n",
    "train_metadata        = pd.read_csv(train_metadata_path, parse_dates=[\"timestamp\"])\n",
    "sample_sub            = pd.read_csv(sample_sub_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8436623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image parameters\n",
    "ROWS     = 128 # Default row size\n",
    "COLS     = 128 # Default col size\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc78d42",
   "metadata": {},
   "source": [
    "### 2.02 Read in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8114f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(image_dir_path, rows, cols, loading_bar=True):\n",
    "    \"\"\"Reads images into np.array from directory of image files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_dir : list\n",
    "        Directory of images to read from.\n",
    "    rows : int\n",
    "        Image height to resize to.\n",
    "    cols : int\n",
    "        Image width to resize to.\n",
    "    loading_bar : bool\n",
    "        Include loading bar or non-verbose.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        Array of images read in.\n",
    "\n",
    "    \"\"\"\n",
    "    # Read image data\n",
    "    image_list = []\n",
    "    \n",
    "    if loading_bar == True:\n",
    "        for chain_id in tqdm(os.listdir(image_dir_path)):\n",
    "            # Each subdirectory is a chain_id\n",
    "            chain_id_dir_path = os.path.join(image_dir_path, chain_id)\n",
    "            # Read images from each chain_id subdirectory\n",
    "            for image in os.listdir(chain_id_dir_path)[0:10]: \n",
    "                # Read image\n",
    "                image_path = os.path.join(chain_id_dir_path, image)\n",
    "                try:\n",
    "                    image = cv2.imread(image_path)\n",
    "                    image = cv2.resize(image, (rows, cols))\n",
    "                    # Append to list of images\n",
    "                    image_list.append(image)    \n",
    "                except:\n",
    "                    pass\n",
    "    elif loading_bar == False:\n",
    "        for chain_id in os.listdir(image_dir_path):\n",
    "            # Each subdirectory is a chain_id\n",
    "            chain_id_dir_path = os.path.join(image_dir_path, chain_id)\n",
    "            # Read images from each chain_id subdirectory\n",
    "            for image in os.listdir(chain_id_dir_path)[0:10]:\n",
    "                # Read image\n",
    "                image_path = os.path.join(chain_id_dir_path, image)\n",
    "                try:\n",
    "                    image = cv2.imread(image_path)\n",
    "                    image = cv2.resize(image, (rows, cols))\n",
    "                    # Append to list of images\n",
    "                    image_list.append(image)    \n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # Convert image list to array\n",
    "    image_list = np.array(image_list)\n",
    "    \n",
    "    return(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a8b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_2(image_dir_path, rows, cols, loading_bar=True):\n",
    "    \"\"\"Reads images into np.array from directory of image files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_dir : list\n",
    "        Directory of images to read from.\n",
    "    rows : int\n",
    "        Image height to resize to.\n",
    "    cols : int\n",
    "        Image width to resize to.\n",
    "    loading_bar : bool\n",
    "        Include loading bar or non-verbose.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        Array of images read in.\n",
    "\n",
    "    \"\"\"\n",
    "    def load_image(image_path):\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (rows, cols))\n",
    "        return image\n",
    "    \n",
    "    # Read image data\n",
    "    image_list = []\n",
    "    \n",
    "    if loading_bar == True:\n",
    "        for chain_id in tqdm(os.listdir(image_dir_path)):\n",
    "            # Each subdirectory is a chain_id\n",
    "            chain_id_dir_path = os.path.join(image_dir_path, chain_id)\n",
    "            # Read images from each chain_id subdirectory\n",
    "            for image in os.listdir(chain_id_dir_path)[0:10]: \n",
    "                # Read image\n",
    "                image_path = os.path.join(chain_id_dir_path, image)\n",
    "                try:\n",
    "                    pool = multiprocessing.Pool(processes=2)\n",
    "                    pool.starmap(load_image, image_path)\n",
    "                    \n",
    "                    # Append to list of images\n",
    "                    image_list.append(image)    \n",
    "                finally:\n",
    "                    pool.close()\n",
    "                    pool.join()\n",
    "\n",
    "    elif loading_bar == False:\n",
    "        for chain_id in os.listdir(image_dir_path):\n",
    "            # Each subdirectory is a chain_id\n",
    "            chain_id_dir_path = os.path.join(image_dir_path, chain_id)\n",
    "            # Read images from each chain_id subdirectory\n",
    "            for image in os.listdir(chain_id_dir_path)[0:10]:\n",
    "                # Read image\n",
    "                image_path = os.path.join(chain_id_dir_path, image)\n",
    "                try:\n",
    "                    pool = multiprocessing.Pool(processes=2)\n",
    "                    pool.starmap(load_image, image_path)\n",
    "                    \n",
    "                    # Append to list of images\n",
    "                    image_list.append(image)    \n",
    "                finally:\n",
    "                    pool.close()\n",
    "                    pool.join()\n",
    "    \n",
    "    # Convert image list to array\n",
    "    image_list = np.array(image_list)\n",
    "    \n",
    "    return(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f015da16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:20<00:00,  4.32it/s]\n"
     ]
    }
   ],
   "source": [
    "train_images = read_images(image_dir_path=train_images_dir_path, rows=ROWS, cols=COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ce375d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/88 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'read_images_2.<locals>.load_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c7f91527593e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_images_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_images_dir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mROWS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCOLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-02953deb2956>\u001b[0m in \u001b[0;36mread_images_2\u001b[0;34m(image_dir_path, rows, cols, loading_bar)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0;31m# Append to list of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         '''\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    422\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m                         \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'read_images_2.<locals>.load_image'"
     ]
    }
   ],
   "source": [
    "train_images = read_images_2(image_dir_path=train_images_dir_path, rows=ROWS, cols=COLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df47f49",
   "metadata": {},
   "source": [
    "## 3.00 Metadata Analysis\n",
    "\n",
    "\n",
    "### 3.01 Initial Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4043ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d2123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271dbbfc",
   "metadata": {},
   "source": [
    "### 3.02 Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac8f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print high level stats on metadata dimensions\n",
    "print(f\"Train metadata dimensions: \\t{train_metadata.shape}\")\n",
    "print(f\"Number of unique records: \\t{len(train_metadata.drop_duplicates())}\")\n",
    "print(f\"Number of unique image names: \\t{train_metadata['image'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ca2e55",
   "metadata": {},
   "source": [
    "There appear to be two duplicated image names, but these aren't considered duplicate records. We'll investigate these two records individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521928e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset duplicated image names - to all records (not just duplicates)\n",
    "train_metadata.loc[train_metadata.groupby(\"image\")[\"image\"].transform(\"count\") > 1, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f58bef0",
   "metadata": {},
   "source": [
    "It looks like these records have indeed been duplicated, and the names have just been switched around. We can remove 1 of each record. \n",
    "\n",
    "Although 2 records don't seem like a lot in the grand scheme of things (i.e. out of 97,554 total records), but every marginal improvement in the data quality is **critical** to model improvement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b756bb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 2 duplicated records\n",
    "train_metadata_dupes = train_metadata.loc[train_metadata.groupby(\"image\")[\"image\"].transform(\"count\") > 1, ]\n",
    "train_metadata_dupes_idx = train_metadata_dupes.iloc[[1, 3]].index\n",
    "train_metadata = train_metadata.drop(train_metadata_dupes_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae53ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe any duplicates using chain, hotel_id and timestamp columns\n",
    "train_metadata[train_metadata.duplicated(\n",
    "    subset=[\"chain\", \"hotel_id\", \"timestamp\"], keep=False\n",
    ")].sort_values([\"chain\", \"hotel_id\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c9b834",
   "metadata": {},
   "source": [
    "Excluding the image column, most images are considered duplicates - this won't actually be the case however. Rather, it can possibly be that the timestamp column is not wholly accurate. Images may have been batch uploaded, or the timestamp column doesn't precisely measure the actual time these images were taken. \n",
    "\n",
    "The timestamp feature will be analysed in more detail to see if there is any value in including this feature as part of our model training. While it is not included as a feature in the test set, if informative, we can use it in our cross validation strategy. \n",
    "\n",
    "And as for possible image duplicates (where the metadata appear unique, but the actual image isn't), this will also be analysed in subsequent sections.\n",
    "\n",
    "### 3.03 Chain ID Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c35aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique chain ids: {train_metadata['chain'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e64210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of chain ids\n",
    "sns.histplot(data=train_metadata, x=\"chain\", stat=\"count\", binwidth=1)\n",
    "plt.xlabel(\"Chain ID\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.title(\"Distribution of Chain IDs in Train Metadata\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6b6cb5",
   "metadata": {},
   "source": [
    "We'll definitely have to stratify by chain during cross validation - there's a heavy 'skew' (there's no particular distribution) towards lower chain ID integers, as well as some increase in counts towards the higher end of chain ID integers also. The middle range appears quite sparse, so we should take extra care not to allow our model to favour only chain IDs in the majority groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display descriptive stats on numbers of records per chain id\n",
    "train_chain_stats = pd.DataFrame(train_metadata[\"chain\"].value_counts())\n",
    "train_chain_stats.describe().rename(columns={\"chain\": \"Chain ID Count Statistics\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dea9f3",
   "metadata": {},
   "source": [
    "Confirming the histogram above, there's a pretty huge standard deviation for number of records per chain id. We'll need to do some significant work and likely have to iterate on this topic to find an optimal solution.\n",
    "\n",
    "Given that the minimum number of records for a chain is 8, it might be useful to look into sampling strategies. We could potentially upsample the low frequency chains and downsample (if needed) the chains with high frequency. This will be explored in later sections and in the modelling notebooks.\n",
    "\n",
    "### 3.04 Hotel ID Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03e566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique hotel ids: {train_metadata['hotel_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f573474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of chain ids\n",
    "sns.histplot(data=train_metadata, x=\"hotel_id\", stat=\"count\", binwidth=100, kde=True)\n",
    "plt.xlabel(\"Hotel ID\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.title(\"Distribution of Hotel IDs in Train Metadata\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f8c98",
   "metadata": {},
   "source": [
    "There appear to be a fairly even distribution of hotel IDs, despite the skews in chain ID. This will be beneficial to modelling. What will be tricky for modelling, is the sheer number of classes (7,770 is a huge number of classes for the size of the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b3e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display descriptive stats on numbers of records per chain id\n",
    "train_hotel_id_stats = pd.DataFrame(train_metadata[\"hotel_id\"].value_counts())\n",
    "train_hotel_id_stats.describe().rename(columns={\"hotel_id\": \"Chain ID Count Statistics\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527362e1",
   "metadata": {},
   "source": [
    "The fact that the standard deviation is less than the mean is promising, in terms of distribution. But a minimum count of hotel ID records of 1, and a maximum of 95, might mean we'll need to explore sampling strategies similar to with chain ID. Stratifying by 7,770 different classes on the other hand might not be feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e225563",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=train_metadata, x=\"hotel_id\", y=\"chain\")\n",
    "plt.xlabel(\"Hotel ID\", fontsize=12)\n",
    "plt.ylabel(\"Chain ID\", fontsize=12)\n",
    "plt.title(\"Hotel ID vs Chain ID\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ba438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation coefficient for Hotel ID and Chain ID\n",
    "coeff, pvalue = stats.pearsonr(train_metadata[\"hotel_id\"], train_metadata[\"chain\"])\n",
    "print(\"Hotel ID and chain ID correlation\")\n",
    "print(f\"Pearson R Correlation Coefficient: {round(coeff, 4)} (p-value: {pvalue})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9375bf8",
   "metadata": {},
   "source": [
    "The above confirms that there is definitely no data leakage occurring between hotel ID and chain ID - which is a good thing when it comes to modelling. An incredibly low Pearson correlation coefficient shows no evidence of a correlation, and an even lower p-value shows this is statistically significant.\n",
    "\n",
    "### 3.05 Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95eaa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year, month and hour from timestamp\n",
    "train_metadata[\"year\"] = train_metadata[\"timestamp\"].dt.year\n",
    "train_metadata[\"month\"] = train_metadata[\"timestamp\"].dt.month\n",
    "train_metadata[\"hour\"] = train_metadata[\"timestamp\"].dt.hour\n",
    "train_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a06a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts for each year\n",
    "datetime_freq = pd.DataFrame(train_metadata[\"year\"].value_counts())\n",
    "datetime_freq = datetime_freq.reset_index().rename(columns={\"year\": \"count\", \"index\": \"year\"}).sort_values(\"year\")\n",
    "\n",
    "# Plot histogram of year\n",
    "sns.barplot(data=datetime_freq, x=\"year\", y=\"count\", color=\"tab:blue\")\n",
    "plt.xlabel(\"Year\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.title(\"Number of Records by Year\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11eb0ad",
   "metadata": {},
   "source": [
    "The data span from 2015 to 2020, and there is some difference in counts for each year - particularly for 2015 and 2020.\n",
    "\n",
    "This may seem unimportant, but given the data source is an app where people can upload photos of their hotel indicates that image data originate from phones. Year-on-year, phone photograph technology has improved dramatically, and the images from 2015 will be noticeably different compared to 2020. It will thus be important to attempt to look into stratifying by year, or figure out how to reconcile this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts for each month\n",
    "datetime_freq = pd.DataFrame(train_metadata[\"month\"].value_counts())\n",
    "datetime_freq = datetime_freq.reset_index().rename(columns={\"month\": \"count\", \"index\": \"month\"})\n",
    "datetime_freq = datetime_freq.sort_values(\"month\")\n",
    "\n",
    "# Plot histogram of year\n",
    "sns.barplot(data=datetime_freq, x=\"month\", y=\"count\", color=\"tab:blue\")\n",
    "plt.xlabel(\"Month\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.title(\"Number of Records by Month\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6552d897",
   "metadata": {},
   "source": [
    "While most months are quite equal in counts, it is unexpected that the summer months of June and July (6 & 7) have the highest numbers. This may not neccessarily affect the model, but it is useful knowledge to have as we might be able to add it to the cross validation strategy. If a robust solution to account for this information in the training strategy is found I imagine it would benefit modelling.\n",
    "\n",
    "The reason why this might make a difference is that there could be some data leakage if we ignore the month. Some seasonal hotels are only open during summer months or vice versa, or at the very least there will be a seasonal factor involved (more images of seaside hotels occur in summer months). There may also be aspects of the image too, such as images are in general higher in brightness during summer months than winter months. Model generalisation will only improve if we can take this into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58acd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts for each hour\n",
    "datetime_freq = pd.DataFrame(train_metadata[\"hour\"].value_counts())\n",
    "datetime_freq = datetime_freq.reset_index().rename(columns={\"hour\": \"count\", \"index\": \"hour\"}).sort_values(\"hour\")\n",
    "\n",
    "# Plot histogram of year\n",
    "sns.barplot(data=datetime_freq, x=\"hour\", y=\"count\", color=\"tab:blue\")\n",
    "plt.xlabel(\"Hour\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.title(\"Number of Records by Hour\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143bc4c1",
   "metadata": {},
   "source": [
    "Interestingly, the above suggests that most images have been taken during darker hours - which will certainly have an impact on the image. Given our reservations about how accurate the time fragment of the timestamp is though, we will have to confirm this using the actual images to see if this is actually the case. It might be the case that images aren't uploaded as they are taken, or that the timestamp may not be the local time for the user, but rather the time logged at the server location. \n",
    "\n",
    "If the data are accurate though, we might want to consider comparing model performance for RGB vs grayscale images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f107da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract is_weekend from timestamp\n",
    "def get_is_weekend(timestamp_col):\n",
    "    \"\"\"\n",
    "    Returns boolean for whether timestamp is a weekend.\n",
    "    \"\"\"\n",
    "    timestamp_col_weekday = timestamp_col.dt.weekday\n",
    "    # Allocate booleans - Weekends are designated 6 & 7\n",
    "    timestamp_col_weekday = timestamp_col_weekday.apply(lambda x: False if x < 5 else True)\n",
    "    \n",
    "    return timestamp_col_weekday\n",
    "\n",
    "train_metadata[\"is_weekend\"] = get_is_weekend(train_metadata[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31087e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts for is_weekend\n",
    "datetime_freq = pd.DataFrame(train_metadata[\"is_weekend\"].value_counts())\n",
    "datetime_freq = datetime_freq.reset_index().rename(columns={\"is_weekend\": \"count\", \"index\": \"is_weekend\"})\n",
    "datetime_freq = datetime_freq.sort_values(\"is_weekend\")\n",
    "\n",
    "datetime_freq.loc[datetime_freq.is_weekend == True, \"is_weekend\"] = \"Weekend\"\n",
    "datetime_freq.loc[datetime_freq.is_weekend == False, \"is_weekend\"] = \"Weekday\"\n",
    "\n",
    "# Plot histogram of year\n",
    "sns.barplot(data=datetime_freq, x=\"is_weekend\", y=\"count\", color=\"tab:blue\")\n",
    "plt.xlabel(\"Weekday or Weekend\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.title(\"Number of Records for Weekends and Weekdays\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd27b5",
   "metadata": {},
   "source": [
    "Given that there are 5 weekdays and only 2 weekends, it's expected that there are more records for weekdays. But this is important to look into, for the same reasons as looking into month. Hotels, such as airport hotels, may have higher frequency of weekday images. Again, however, we cannot profess to know based on the competition information whether users are uploading images as soon as they are taken - they could be taken and uploaded as a batch following the visit. This feature of the data could be useful, depending on data quality, but won't be prioritised over the less granular features created from timestamp - such as year and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94724e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correlation coefficients for all features\n",
    "corr = train_metadata.drop([\"image\", \"timestamp\"], axis=1).corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "sns.heatmap(data=corr, annot=True, linewidths=0.5, mask=mask)\n",
    "plt.title(\"Corrplot of Train Metadata Features\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb336cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_metadata_dupes, train_metadata_dupes_idx, train_chain_stats, train_hotel_id_stats, coeff\n",
    "del pvalue, datetime_freq, corr, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a379c387",
   "metadata": {},
   "source": [
    "The above confirms that there are no correlations that we should be aware of (particularly in terms of how hotel ID and chain ID integers are allocated).\n",
    "\n",
    "## 4.00 Train Images\n",
    "\n",
    "TODO:\n",
    " - rgb distribution\n",
    " - avg rgb by chain\n",
    " - avg rgb by month\n",
    " - rgb distribution by month (2 plots for dec and jul)\n",
    " - image brightness by hour (https://stackoverflow.com/questions/14243472/estimate-brightness-of-an-image-opencv)\n",
    " - image brightness by month\n",
    " \n",
    " - Anomaly detection (https://github.com/SIlvaMFPedro/pyimagesearch/tree/master/anomaly-detection)\n",
    " - Detect low contrast images (https://github.com/SIlvaMFPedro/pyimagesearch/tree/master/detect-low-contrast)\n",
    " - Colour correction (https://github.com/SIlvaMFPedro/pyimagesearch/tree/master/opencv-color-correction)\n",
    " \n",
    " \n",
    "### 4.01 RGB Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335144b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd62e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea6611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8009609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d149ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bba0db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a32ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b0f27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4530a79f",
   "metadata": {},
   "source": [
    "### Image Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!time python3 ../input/multiprocessing_images/extract.py --images ../input/multiprocessing_images/images \\\n",
    "--output ../input/multiprocessing_images/temp_output --hashes ../input/multiprocessing_images/hashes.pickle\n",
    "\n",
    "pd.read_pickle(r'../input/multiprocessing_images/hashes.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf9aa16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e12291e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069091f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ad4246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3ed296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c5c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3981ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23cddb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc99ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5738a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b907aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8780acb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ee069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f7fe9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-assignment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-retreat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-specification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-selection",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
