{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae7992a",
   "metadata": {},
   "source": [
    "# Hotel Recognition to Combat Human Trafficking | Train\n",
    "    2021-05-09\n",
    "    Edward Sims\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1.00 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf182792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import cv2\n",
    "from datetime import datetime as dt\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "import multiprocessing\n",
    "\n",
    "# Data vis packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Modelling packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as k\n",
    "# Key layers\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Flatten\n",
    "# Activation layers\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU, ELU, ThresholdedReLU\n",
    "# Dropout layers\n",
    "from tensorflow.keras.layers import Dropout, AlphaDropout, GaussianDropout\n",
    "# Normalisation layers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "# Embedding layers\n",
    "from tensorflow.keras.layers import Embedding, Concatenate, Reshape\n",
    "# Callbacks\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
    "# Optimisers\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "# Model cross validation and evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "# For Bayesian hyperparameter searching\n",
    "from skopt import gbrt_minimize, gp_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# Package options\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "plt.rcParams[\"figure.figsize\"] = [14, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8795e543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs Available: 1\n",
      "REPLICAS: 1\n",
      "Number of CPU Cores: 64\n"
     ]
    }
   ],
   "source": [
    "# Check GPU config\n",
    "print(f\"Number of GPUs Available: {len(tf.config.experimental.list_physical_devices('GPU'))}\")\n",
    "\n",
    "strategy = tf.distribute.get_strategy()\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')\n",
    "\n",
    "# Data access\n",
    "gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n",
    "\n",
    "# Get number of cpu cores for multiprocessing\n",
    "try:\n",
    "    cpus = int(multiprocessing.cpu_count() / 2)\n",
    "except NotImplementedError:\n",
    "    cpus = 1 # Default number of cores\n",
    "    \n",
    "print(f\"Number of CPU Cores: {cpus}\")\n",
    "\n",
    "# Disable eager execution for mAP metric\n",
    "#tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d8c86",
   "metadata": {},
   "source": [
    "## 2.00 Data Preparation\n",
    "### 2.01 Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b90807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "data_dir_path         = \"../input/hotel-id-2021-fgvc8\"\n",
    "train_images_dir_path = os.path.join(data_dir_path, \"train_images\")\n",
    "test_images_dir_path  = os.path.join(data_dir_path, \"test_images\")\n",
    "\n",
    "train_metadata_path   = os.path.join(data_dir_path, \"train.csv\")\n",
    "sample_sub_path       = os.path.join(data_dir_path, \"sample_submission.csv\")\n",
    "\n",
    "# Read csv data\n",
    "train_metadata        = pd.read_csv(train_metadata_path, parse_dates=[\"timestamp\"])\n",
    "sample_sub            = pd.read_csv(sample_sub_path)\n",
    "\n",
    "# Remove 2 duplicated records from metadata\n",
    "train_metadata_dupes = train_metadata.loc[train_metadata.groupby(\"image\")[\"image\"].transform(\"count\") > 1, ]\n",
    "train_metadata_dupes_idx = train_metadata_dupes.iloc[[1, 3]].index\n",
    "train_metadata = train_metadata.drop(train_metadata_dupes_idx, axis=0)\n",
    "\n",
    "train_metadata = train_metadata.sort_values(\"hotel_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95040f",
   "metadata": {},
   "source": [
    "### 2.02 Set default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fc440d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: baseline_xception_128x128_3folds_seed14\n"
     ]
    }
   ],
   "source": [
    "# Define key parameters\n",
    "SEED = 14\n",
    "np.random.seed(SEED)\n",
    "\n",
    "ROWS     = 128 # Default row size\n",
    "COLS     = 128 # Default col size\n",
    "CHANNELS = 3\n",
    "\n",
    "EPOCHS     = 100\n",
    "BATCH_SIZE = 64\n",
    "PATIENCE   = 10\n",
    "\n",
    "# Read all images in and subset in CV? Or Read images inside each fold in CV?\n",
    "read_images_in_fold = True\n",
    "# Treat model as baseline or not\n",
    "is_baseline = True\n",
    "\n",
    "# Uncomment as appropriate\n",
    "#MODEL_TO_USE = \"densenet121\"\n",
    "#MODEL_TO_USE = \"densenet169\"\n",
    "#MODEL_TO_USE = \"densenet201\"\n",
    "#MODEL_TO_USE = \"efficientnet_b0\"\n",
    "#MODEL_TO_USE = \"efficientnet_b1\"\n",
    "#MODEL_TO_USE = \"efficientnet_b2\"\n",
    "#MODEL_TO_USE = \"efficientnet_b3\"\n",
    "#MODEL_TO_USE = \"efficientnet_b4\"\n",
    "#MODEL_TO_USE = \"efficientnet_b5\"\n",
    "#MODEL_TO_USE = \"inception_resnetv2\"\n",
    "#MODEL_TO_USE = \"inceptionv3\"\n",
    "#MODEL_TO_USE = \"resnet50v2\"\n",
    "#MODEL_TO_USE = \"resnet101v2\"\n",
    "#MODEL_TO_USE = \"resnext50\"\n",
    "#MODEL_TO_USE = \"resnext101\"\n",
    "#MODEL_TO_USE = \"resnet152v2\"\n",
    "#MODEL_TO_USE = \"vgg19\"\n",
    "MODEL_TO_USE = \"xception\"\n",
    "\n",
    "kfold_params = {\n",
    "    0: {\"ROWS\": ROWS,\"COLS\": COLS},\n",
    "    1: {\"ROWS\": ROWS,\"COLS\": COLS},\n",
    "    2: {\"ROWS\": ROWS,\"COLS\": COLS},\n",
    "    #3: {\"ROWS\": ROWS,\"COLS\": COLS},\n",
    "    #4: {\"ROWS\": ROWS,\"COLS\": COLS},\n",
    "    #5: {\"ROWS\": ROWS,\"COLS\": COLS},\n",
    "    #6: {\"ROWS\": ROWS,\"COLS\": COLS},\n",
    "    #7: {\"ROWS\": ROWS,\"COLS\": COLS}\n",
    "}\n",
    "\n",
    "KFOLDS = len(kfold_params)\n",
    "\n",
    "if is_baseline == True:\n",
    "    model_name_save = f\"baseline_{MODEL_TO_USE}_{str(ROWS)}x{str(COLS)}_{str(KFOLDS)}folds_seed{str(SEED)}\"\n",
    "elif is_baseline == False:\n",
    "    model_name_save = f\"{MODEL_TO_USE}_{str(ROWS)}x{str(COLS)}_{str(KFOLDS)}folds_seed{str(SEED)}\"\n",
    "\n",
    "# Create models path if does not exist already\n",
    "if not os.path.exists(f\"models/{model_name_save}\"):\n",
    "    os.mkdir(f\"models/{model_name_save}\")\n",
    "\n",
    "print(f\"Model name: {model_name_save}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e37b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata preparation\n",
    "def get_is_weekend(timestamp_col):\n",
    "    \"\"\"\n",
    "    Returns boolean for whether timestamp is a weekend.\n",
    "    \"\"\"\n",
    "    timestamp_col_weekday = timestamp_col.dt.weekday\n",
    "    # Allocate booleans - Weekends are designated 6 & 7\n",
    "    timestamp_col_weekday = timestamp_col_weekday.apply(lambda x: False if x < 5 else True)\n",
    "    \n",
    "    return timestamp_col_weekday\n",
    "\n",
    "# Extract year, month and hour from timestamp feature\n",
    "train_metadata[\"year\"] = train_metadata[\"timestamp\"].dt.year\n",
    "train_metadata[\"month\"] = train_metadata[\"timestamp\"].dt.month\n",
    "train_metadata[\"hour\"] = train_metadata[\"timestamp\"].dt.hour\n",
    "# Extract is_weekend from timestamp\n",
    "train_metadata[\"is_weekend\"] = get_is_weekend(train_metadata[\"timestamp\"])\n",
    "train_metadata = train_metadata.drop(\"timestamp\", axis=1)\n",
    "\n",
    "# Extract labels from metadata\n",
    "y_train_vector = np.array(train_metadata[\"hotel_id\"])\n",
    "y_train = np.zeros((y_train_vector.size, y_train_vector.max() + 1))\n",
    "y_train[np.arange(y_train_vector.size), y_train_vector] = 1\n",
    "\n",
    "num_classes = len(np.unique(y_train_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9fa5d",
   "metadata": {},
   "source": [
    "### 2.03 Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa8bf33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths(image_dir_path):\n",
    "    \"\"\"Reads images into np.array from directory of image files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_dir : list\n",
    "        Directory of images to read from.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        List of images paths to.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get list of all image paths\n",
    "    image_path_list = []\n",
    "    try:\n",
    "        for chain_id in os.listdir(image_dir_path):\n",
    "            # Each subdirectory is a chain_id\n",
    "            chain_id_dir_path = os.path.join(image_dir_path, chain_id)\n",
    "            # Read images from each chain_id subdirectory\n",
    "            for image in os.listdir(chain_id_dir_path): \n",
    "                # Read image\n",
    "                image_path = os.path.join(chain_id_dir_path, image)\n",
    "                # Append to list of images\n",
    "                image_path_list.append(image_path)\n",
    "    except NotADirectoryError:\n",
    "        # Read images from each chain_id subdirectory\n",
    "        for image in os.listdir(image_dir_path): \n",
    "            # Read image\n",
    "            image_path = os.path.join(image_dir_path, image)\n",
    "            # Append to list of images\n",
    "            image_path_list.append(image_path)\n",
    "\n",
    "    # Remove all non-jpg files\n",
    "    for idx, path in enumerate(image_path_list):\n",
    "        if \".jpg\" not in path and \".png\" not in path:\n",
    "            del image_path_list[idx]\n",
    "    \n",
    "    return image_path_list\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    Read and return single resized image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return image\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def read_images(images_paths):\n",
    "    # Read in train and test images asynchrously\n",
    "    pool = multiprocessing.Pool(processes=cpus)\n",
    "    images_array = np.array(pool.map(load_image, images_paths))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    return images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca3a7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all full image paths\n",
    "train_images_path_list = get_image_paths(train_images_dir_path)\n",
    "test_images_path_list = get_image_paths(test_images_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9355a2",
   "metadata": {},
   "source": [
    "### 2.04 Image Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fe27c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_imgs(train_imgs, test_imgs, verbose=0):\n",
    "    \"\"\"Centers images by minusing the mean and dividing by std\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_imgs : array \n",
    "        Train images to read in and normalise\n",
    "    test_imgs : array\n",
    "        Test images to read in and normalise\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        2 np.arrays including original images and augmented images (for train and test set).\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose == 1:\n",
    "        print(\"Preprocessing images...\\n\")\n",
    "    # Convert pixel values to float\n",
    "    train_imgs = train_imgs.astype(float)\n",
    "    test_imgs = test_imgs.astype(float)\n",
    "\n",
    "    # Get per-channel means and stds    \n",
    "    train_means = train_imgs.reshape(-1, train_imgs.shape[-1]).mean(axis=0)\n",
    "    train_stds = train_imgs.reshape(-1, train_imgs.shape[-1]).std(axis=0)\n",
    "\n",
    "    # Standardise images\n",
    "    train_imgs -= train_means\n",
    "    train_imgs /= train_stds\n",
    "    \n",
    "    test_imgs -= train_means\n",
    "    test_imgs /= train_stds\n",
    "    \n",
    "    if verbose == 1:\n",
    "        print(f\"Train per-channel means: {train_imgs.reshape(-1, train_imgs.shape[-1]).mean(axis=0)}\")\n",
    "        print(f\"Trin per-channel stds: {train_imgs.reshape(-1, train_imgs.shape[-1]).std(axis=0)}\")\n",
    "\n",
    "    return train_imgs, test_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1fb2191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_augmentations(train_imgs, y, p, aug, verbose=0):\n",
    "    \"\"\"Make a random subset of p proportion. Apply augmentations\n",
    "        to the subset and append back to the original dataset, \n",
    "        making necessary changes to labels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_imgs : array\n",
    "        Train images to read in and augment\n",
    "    y : array\n",
    "        Train labels to copy as per augmented images\n",
    "    p : float\n",
    "        sample size probability\n",
    "    aug : string\n",
    "        Choice of augmentation from ['fliplr', 'rot90', 'rot180']\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        np.array of original images and augmented images and their corresponding labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose == 1:\n",
    "        print('Augmenting images...')\n",
    "    # Get a sample of X and y based on p proportion\n",
    "    sample_size = int(round(len(y) * p))\n",
    "    idx_sample = random.sample(range(0, len(y), 1), sample_size)\n",
    "\n",
    "    # Make augmentations to sample\n",
    "    if aug == \"fliplr\":\n",
    "        train_imgs = np.concatenate(\n",
    "            (train_imgs, np.array([np.fliplr(train_imgs[i]) for i in idx_sample])),\n",
    "            axis=0\n",
    "        )\n",
    "    elif aug == \"rot90\":\n",
    "        train_imgs = np.concatenate(\n",
    "            (train_imgs, np.array([np.rot90(train_imgs[i], 1) for i in idx_sample])),\n",
    "            axis=0\n",
    "        )\n",
    "    elif aug == \"rot180\":\n",
    "        train_imgs = np.concatenate(\n",
    "            (train_imgs, np.array([np.rot90(train_imgs[i], 2) for i in idx_sample])),\n",
    "            axis=0\n",
    "        )\n",
    "    \n",
    "    elif aug == \"rot270\":\n",
    "        train_imgs = np.concatenate(\n",
    "            (train_imgs, np.array([np.rot90(train_imgs[i], 3) for i in idx_sample])),\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "    \n",
    "    # Copy labels accordingly\n",
    "    y_sample = np.array([y[i] for i in idx_sample])\n",
    "    y = np.concatenate((y, y_sample), axis=0)\n",
    "\n",
    "    return train_imgs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88005137",
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_images_in_fold == False:\n",
    "    train_images = read_images(train_images_path_list)\n",
    "    test_images  = read_images(test_images_path_list)\n",
    "    print(f\"Train images shape: {train_images.shape}\")\n",
    "    print(f\"Test images shape:  {test_images.shape}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b674d633",
   "metadata": {},
   "source": [
    "## 3.00 Modelling\n",
    "### 3.01 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b31899b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_lrfn(lr_start          = 0.00001, \n",
    "               lr_max            = 0.0008, \n",
    "               lr_min            = 0.00001, \n",
    "               lr_rampup_epochs  = 20, \n",
    "               lr_sustain_epochs = 0, \n",
    "               lr_exp_decay      = 0.8):\n",
    "    \n",
    "    lr_max = lr_max * strategy.num_replicas_in_sync\n",
    "\n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_rampup_epochs:\n",
    "            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
    "        return lr\n",
    "\n",
    "    return lrfn\n",
    "\n",
    "lrfn = build_lrfn()\n",
    "lr = LearningRateScheduler(lrfn, verbose=0)\n",
    "\n",
    "plt.plot([lrfn(epoch) for epoch in range(EPOCHS)])\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc2b06",
   "metadata": {},
   "source": [
    "### 3.02 Compiler Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b053897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Mean Average Precision at K metric\n",
    "map_at_k = tf.compat.v1.metrics.average_precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0df631bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_true = np.array([[4], [4], [4], [4], [4]]).astype(np.int64)\n",
    "#y_true = tf.identity(y_true)\n",
    "#\n",
    "#y_pred = np.array([[0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.1, 0.2, 0.6],\n",
    "#                   [0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.1, 0.2, 0.6],\n",
    "#                   [0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.1, 0.2, 0.6],\n",
    "#                   [0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.1, 0.2, 0.6],\n",
    "#                   [0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.1, 0.2, 0.6]\n",
    "#                   ]).astype(np.float32)\n",
    "#y_pred = tf.identity(y_pred)\n",
    "#\n",
    "#_, m_ap = map_at_k(y_true, y_pred, 5)\n",
    "#\n",
    "#sess = tf.Session()\n",
    "#sess.run(tf.local_variables_initializer())\n",
    "#\n",
    "#stream_vars = [i for i in tf.local_variables()]\n",
    "#\n",
    "#tf_map = sess.run(m_ap)\n",
    "#print(tf_map)\n",
    "#\n",
    "#tmp_rank = tf.nn.top_k(y_pred, 5)\n",
    "#\n",
    "#print(sess.run(tmp_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5593ee76",
   "metadata": {},
   "source": [
    "### 3.03 CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73139d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model we'll feed the images into before concatenation\n",
    "def get_cnn_model(kfold, model_to_use=MODEL_TO_USE, verbose=1):\n",
    "    \"\"\"Get the pretrained CNN model specified.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    kfold : int \n",
    "        Fold that the CV is currently on (to determine img size)\n",
    "    model_to_use : str \n",
    "        Model to retrieve\n",
    "    verbose : int\n",
    "        Level of output communication. 0=None, 1=All.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model_return : \n",
    "    \"\"\"\n",
    "    if verbose == 1:\n",
    "        print(\"\\nLoading pretrained model...\")\n",
    "                        \n",
    "    input_shape = (\n",
    "        kfold_params[kfold][\"ROWS\"],\n",
    "        kfold_params[kfold][\"COLS\"],\n",
    "        CHANNELS\n",
    "    )\n",
    "    \n",
    "    # DenseNet121\n",
    "    if model_to_use == \"densenet121\":\n",
    "        from tensorflow.keras.applications import DenseNet121\n",
    "        model_return = DenseNet121(input_shape=input_shape, include_top=False)\n",
    "        \n",
    "    # DenseNet169\n",
    "    elif model_to_use == \"densenet169\":\n",
    "        from tensorflow.keras.applications import DenseNet169\n",
    "        model_return = DenseNet169(input_shape=input_shape, include_top=False)\n",
    "        \n",
    "    # DenseNet201\n",
    "    elif model_to_use == \"densenet201\":\n",
    "        from tensorflow.keras.applications import DenseNet201\n",
    "        model_return = DenseNet201(input_shape=input_shape, include_top=False)\n",
    "            \n",
    "    # EfficientNet_B0\n",
    "    elif model_to_use == \"efficientnet_b0\":\n",
    "        import efficientnet.tfkeras as efficientnet\n",
    "        model_return = efficientnet.EfficientNetB0(\n",
    "            input_shape=input_shape, include_top=False\n",
    "        )\n",
    "    \n",
    "    # EfficientNet_B1\n",
    "    elif model_to_use == \"efficientnet_b1\":\n",
    "        import efficientnet.tfkeras as efficientnet\n",
    "        model_return = efficientnet.EfficientNetB1(\n",
    "            input_shape=input_shape, include_top=False\n",
    "        )\n",
    "            \n",
    "    # EfficientNet_B2\n",
    "    elif model_to_use == \"efficientnet_b2\":\n",
    "        import efficientnet.tfkeras as efficientnet\n",
    "        model_return = efficientnet.EfficientNetB2(\n",
    "            input_shape=input_shape, include_top=False\n",
    "        )\n",
    "            \n",
    "    # EfficientNet_B3\n",
    "    elif model_to_use == \"efficientnet_b3\":\n",
    "        import efficientnet.tfkeras as efficientnet\n",
    "        model_return = efficientnet.EfficientNetB3(\n",
    "            input_shape=input_shape, include_top=False\n",
    "        )\n",
    "            \n",
    "    # EfficientNet_B4\n",
    "    elif model_to_use == \"efficientnet_b4\":\n",
    "        import efficientnet.tfkeras as efficientnet\n",
    "        model_return = efficientnet.EfficientNetB4(\n",
    "            input_shape=input_shape, include_top=False\n",
    "        )\n",
    "            \n",
    "    # EfficientNet_B5\n",
    "    elif model_to_use == \"efficientnet_b5\":\n",
    "        import efficientnet.tfkeras as efficientnet\n",
    "        model_return = efficientnet.EfficientNetB5(\n",
    "            input_shape=input_shape, include_top=False\n",
    "        )\n",
    "\n",
    "    # InceptionResNetV2\n",
    "    elif model_to_use == \"inception_resnetv2\":\n",
    "        from tensorflow.keras.applications import InceptionResNetV2\n",
    "        model_return = InceptionResNetV2(input_shape=input_shape, include_top=False)\n",
    "\n",
    "    # InceptionV3\n",
    "    elif model_to_use == \"inceptionv3\":\n",
    "        from tensorflow.keras.applications import InceptionV3\n",
    "        model_return = InceptionV3(input_shape=input_shape, include_top=False)\n",
    "    \n",
    "    # NasNetLarge\n",
    "    elif model_to_use == \"nasnetlarge\":\n",
    "        from tensorflow.keras.applications import NASNetLarge\n",
    "        model_return = NASNetLarge(input_shape=input_shape, include_top=False)\n",
    "        \n",
    "    # ResNet50V2\n",
    "    elif model_to_use == \"resnet50v2\":\n",
    "        from tensorflow.keras.applications import ResNet50V2\n",
    "        model_return = ResNet50V2(input_shape=input_shape, include_top=False)\n",
    "\n",
    "    # ResNet101V2\n",
    "    elif model_to_use == \"resnet101v2\":\n",
    "        from tensorflow.keras.applications import ResNet101V2\n",
    "        model_return = ResNet101V2(input_shape=input_shape, include_top=False)\n",
    "\n",
    "    # ResNet152V2\n",
    "    elif model_to_use == \"resnet152v2\":\n",
    "        from tensorflow.keras.applications import ResNet152V2\n",
    "        model_return = ResNet152V2(input_shape=input_shape, include_top=False)\n",
    "\n",
    "    # ResNeXt50\n",
    "    elif model_to_use == \"resnext50\":\n",
    "        from keras_applications.resnext import ResNeXt50\n",
    "        model_return = ResNeXt50(\n",
    "            input_shape=input_shape, \n",
    "            include_top=False, \n",
    "            classes=classes,\n",
    "            backend=keras.backend, \n",
    "            layers=keras.layers, \n",
    "            models=keras.models, \n",
    "            utils=keras.utils\n",
    "        )\n",
    "\n",
    "    # ResNeXt101\n",
    "    elif model_to_use == \"resnext101\":\n",
    "        from keras_applications.resnext import ResNeXt101\n",
    "        model_return = ResNeXt101(\n",
    "            input_shape=input_shape, \n",
    "            include_top=False, \n",
    "            classes=classes,\n",
    "            backend=keras.backend, \n",
    "            layers=keras.layers, \n",
    "            models=keras.models, \n",
    "            utils=keras.utils\n",
    "        )\n",
    "        \n",
    "    # VGG19\n",
    "    elif model_to_use == \"vgg19\":\n",
    "        from tensorflow.keras.applications import VGG19\n",
    "        model_return = VGG19(input_shape=input_shape, include_top=False)\n",
    "\n",
    "    # Xception\n",
    "    elif model_to_use == \"xception\":\n",
    "        from tensorflow.keras.applications import Xception\n",
    "        model_return = Xception(input_shape=input_shape, include_top=False)\n",
    "        \n",
    "    return model_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba26be4b",
   "metadata": {},
   "source": [
    "### 3.04 Stratified Group Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a15b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_group_k_fold(X, y, groups, k, seed=SEED):\n",
    "    \"\"\"https://www.kaggle.com/jakubwasikowski/stratified-group-k-fold-cross-validation\"\"\"\n",
    "    labels_num = np.max(y) + 1\n",
    "    y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "    y_distr = Counter()\n",
    "    for label, g in zip(y, groups):\n",
    "        y_counts_per_group[g][label] += 1\n",
    "        y_distr[label] += 1\n",
    "\n",
    "    y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "    groups_per_fold = defaultdict(set)\n",
    "\n",
    "    def eval_y_counts_per_fold(y_counts, fold):\n",
    "        y_counts_per_fold[fold] += y_counts\n",
    "        std_per_label = []\n",
    "        for label in range(labels_num):\n",
    "            label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n",
    "            std_per_label.append(label_std)\n",
    "        y_counts_per_fold[fold] -= y_counts\n",
    "        return np.mean(std_per_label)\n",
    "    \n",
    "    groups_and_y_counts = list(y_counts_per_group.items())\n",
    "    random.Random(seed).shuffle(groups_and_y_counts)\n",
    "\n",
    "    for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "        best_fold = None\n",
    "        min_eval = None\n",
    "        for i in range(k):\n",
    "            fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "            if min_eval is None or fold_eval < min_eval:\n",
    "                min_eval = fold_eval\n",
    "                best_fold = i\n",
    "        y_counts_per_fold[best_fold] += y_counts\n",
    "        groups_per_fold[best_fold].add(g)\n",
    "\n",
    "    all_groups = set(groups)\n",
    "    for i in range(k):\n",
    "        train_groups = all_groups - groups_per_fold[i]\n",
    "        test_groups = groups_per_fold[i]\n",
    "\n",
    "        train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "        test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "        yield train_indices, test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7da111",
   "metadata": {},
   "source": [
    "### 3.05 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8a9620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Generates data for Keras\n",
    "    \"\"\"\n",
    "    def __init__(self, list_IDs, labels, batch_size=BATCH_SIZE, dim=(len(y_train), ROWS, COLS), \n",
    "                 n_channels=CHANNELS, n_classes=num_classes, shuffle=True):\n",
    "        \"Initialization\"\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Denotes the number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Generate one batch of data\n",
    "        \"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index *self.batch_size: (index + 1) *self.batch_size]\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Updates indexes after each epoch\n",
    "        \"\"\"\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "            \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        \"\"\"\n",
    "        Generates data containing batch_size samples\n",
    "        \"\"\" \n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.load(f\"data/{ID}.npy\")\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_in_fold_data(kfold, tdx, vdx, read_images_in_fold=read_images_in_fold):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    kfold : int\n",
    "        the current fold in CV\n",
    "    tdx : list\n",
    "        train indices for the current fold\n",
    "    vdx : list\n",
    "        validation indices for the current fold\n",
    "    read_images_in_fold : bool \n",
    "        whether to read the images inside or outside of folds\n",
    "    loading_bar : bool\n",
    "        include a loading bar when loading CV images\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Fetching data...')\n",
    "    \n",
    "    # Get image paths\n",
    "    X_path, X_path_val, = np.array(train_images_path_list)[tdx], np.array(train_images_path_list)[vdx]\n",
    "    # Get values for target\n",
    "    y, y_val = y_train[tdx], y_train[vdx]        \n",
    "    \n",
    "    if read_images_in_fold == False:\n",
    "        # Get values for imgs\n",
    "        X_img = np.array(\n",
    "            [cv2.resize(\n",
    "                img, \n",
    "                (kfold_params[kfold][\"ROWS\"], # Row size for current fold\n",
    "                 kfold_params[kfold][\"COLS\"]) # Col size for current fold\n",
    "            ) for img in train_images[tdx]]\n",
    "        )\n",
    "        X_img_val = np.array(\n",
    "            [cv2.resize(\n",
    "                img, \n",
    "                (kfold_params[kfold][\"ROWS\"], # Row size for current fold\n",
    "                 kfold_params[kfold][\"COLS\"]) # Col size for current fold\n",
    "            ) for img in train_images[vdx]]\n",
    "        )\n",
    "            \n",
    "    elif read_images_in_fold == True:\n",
    "        # Read images in from scratch\n",
    "        X_img = np.array(\n",
    "            [cv2.resize(\n",
    "                img, \n",
    "                (kfold_params[kfold][\"ROWS\"], # Row size for current fold\n",
    "                 kfold_params[kfold][\"COLS\"]) # Col size for current fold\n",
    "            ) for img in read_images(X_path)]\n",
    "        )\n",
    "        \n",
    "        X_img_val = np.array(\n",
    "            [cv2.resize(\n",
    "                img, \n",
    "                (kfold_params[kfold][\"ROWS\"], # Row size for current fold\n",
    "                 kfold_params[kfold][\"COLS\"]) # Col size for current fold\n",
    "            ) for img in read_images(X_path_val)]\n",
    "        )\n",
    "    \n",
    "    return X_img, X_img_val, y, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_augmentations(img):\n",
    "    \"\"\"\n",
    "    Returns augmented image(s) and original.\n",
    "    \"\"\"\n",
    "    img_augs = np.concatenate(\n",
    "        (\n",
    "            np.expand_dims(img, axis=0),\n",
    "            np.expand_dims(np.rot90(img, 1), axis=0),\n",
    "            np.expand_dims(np.rot90(img, 2), axis=0),\n",
    "            np.expand_dims(np.rot90(img, 3), axis=0),\n",
    "            np.expand_dims(np.fliplr(img), axis=0),\n",
    "            np.expand_dims(np.fliplr(np.rot90(img, 1)), axis=0),\n",
    "            np.expand_dims(np.fliplr(np.rot90(img, 2)), axis=0),\n",
    "            np.expand_dims(np.fliplr(np.rot90(img, 3)), axis=0)),\n",
    "        axis=0\n",
    "    )\n",
    "        \n",
    "    return(img_augs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad838ad6",
   "metadata": {},
   "source": [
    "### 3.06 Define and Train Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6971dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_model(kfold, model_cnn=MODEL_TO_USE, verbose=1):\n",
    "    model_cnn = get_cnn_model(kfold, model_cnn)\n",
    "    # Add a global spatial average pooling layer\n",
    "    x = model_cnn.output\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    # Define output layer\n",
    "    output = Dense(y_train.shape[1], activation=\"softmax\")(x)\n",
    "    # Define final model\n",
    "    model = Model(inputs=model_cnn.input, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2668a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_baseline == True:\n",
    "    # Define CV strategy\n",
    "    kf = KFold(n_splits=KFOLDS, shuffle=True, random_state=SEED)\n",
    "    loss_scores = []\n",
    "    best_params = pd.DataFrame(columns=[\"kfold\", \"seed\"])\n",
    "\n",
    "    for fold, (tdx, vdx) in enumerate(kf.split(train_images_path_list[0:500], y_train[0:500])):\n",
    "        print(f\"FOLD {fold}\")\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "        # Create name to save model by\n",
    "        model_save_path = f\"models/{model_name_save}/{model_name_save}_{str(fold)}.h5\"\n",
    "        model_save_path_temp = f\"models/{model_name_save}/TEMP_{model_name_save}_{str(fold)}.h5\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Parameters\n",
    "        params = {\n",
    "            \"dim\": (len(y_train), ROWS, COLS),\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"n_classes\": num_classes,\n",
    "            \"n_channels\": CHANNELS,\n",
    "            \"shuffle\": True\n",
    "        }\n",
    "\n",
    "        # Datasets\n",
    "        partition = #\n",
    "        #labels = # Labels\n",
    "        #\n",
    "        ## Generators\n",
    "        #training_generator = DataGenerator(partition[\"train\"], labels, **params)\n",
    "        #validation_generator = DataGenerator(partition[\"validation\"], labels, **params)\n",
    "\n",
    "        # Design model\n",
    "        #model = Sequential()\n",
    "        #[...] # Architecture\n",
    "        #model.compile()\n",
    "        #\n",
    "        ## Train model on dataset\n",
    "        #model.fit_generator(generator=training_generator,\n",
    "        #                    validation_data=validation_generator,\n",
    "        #                    use_multiprocessing=True,\n",
    "        #                    workers=6)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Fetch in-fold data\n",
    "        #X_tdx, X_vdx, y_tdx, y_vdx = get_in_fold_data(fold, tdx, vdx)\n",
    "        #\n",
    "        # Get baseline model\n",
    "        #model = get_baseline_model(fold)\n",
    "        #\n",
    "        ## Compile model\n",
    "        #model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "    #\n",
    "        ## Define learning rate schedule\n",
    "        #lr = LearningRateScheduler(lrfn, verbose=0)\n",
    "        #\n",
    "        ## Define early stopping parameters\n",
    "        #es = EarlyStopping(\n",
    "        #    monitor=\"val_loss\", \n",
    "        #    mode=\"min\",\n",
    "        #    restore_best_weights=True, \n",
    "        #    verbose=0, \n",
    "        #    patience=PATIENCE\n",
    "        #)\n",
    "        #\n",
    "        ## Define model checkpoint parameters\n",
    "        #mc = ModelCheckpoint(\n",
    "        #    filepath=model_save_path_temp, \n",
    "        #    save_best_only=True, \n",
    "        #    save_weights_only=False,\n",
    "        #    monitor=\"val_loss\", \n",
    "        #    mode=\"min\",\n",
    "        #    verbose=0\n",
    "        #)\n",
    "    #\n",
    "        # Fit model\n",
    "        #print(\"TRAINING...\")\n",
    "        #history = model.fit(\n",
    "        #    X_tdx, y_tdx,\n",
    "        #    epochs=EPOCHS,\n",
    "        #    batch_size=BATCH_SIZE,\n",
    "        #    callbacks = [es, lr, mc],\n",
    "        #    verbose=0,\n",
    "        #    validation_split=0.25\n",
    "        #)\n",
    "        #    \n",
    "        ## Get val_loss for the best model (one saved with ModelCheckpoint)\n",
    "        #loss = min(history.history[\"val_loss\"])\n",
    "        #print(f\"CURRENT LOSS: \\t\\t{loss}\")\n",
    "        \n",
    "        #    # If the classification loss of the saved model is improved\n",
    "        #    if loss < best_loss:\n",
    "        #        model.save(model_save_name)\n",
    "        #        best_loss = loss\n",
    "        #        \n",
    "        #        # Save transformed validation arrays (so they can be used for prediction)\n",
    "        #        global X_vdx_best_model, y_vdx_best_model\n",
    "        #        X_vdx_best_model, y_vdx_best_model = X_vdx, y_vdx\n",
    "        #        \n",
    "        #        ### SAVE MODEL PARAMETERS ### \n",
    "        #        best_params = best_params.loc[best_params.kfold != fold]\n",
    "        #        best_params = best_params.append({'kfold'            : fold,\n",
    "        #                                          'selected_features': selected_features,\n",
    "        #                                          'num_features'     : NUM_FEATURES,\n",
    "        #                                          'num_components'   : NUM_COMPONENTS,\n",
    "        #                                          'use_embedding'    : USE_EMBEDDING,\n",
    "        #                                          'seed'             : SEED}, \n",
    "        #                                         ignore_index=True)\n",
    "        #        best_params.to_csv('final_classifier_parameters/' + model_name_save + '.csv', index=False)\n",
    "        #        \n",
    "        #    print(f'BEST LOSS: \\t\\t{best_loss}\\n')\n",
    "    #\n",
    "        #    del model\n",
    "        #    k.clear_session()\n",
    "        #    return(loss)\n",
    "        #\n",
    "        ### RUN BAYESIAN HYPERPARAMETER SEARCH ##\n",
    "        #print('RUNNING PARAMETER SEARCH...\\n')\n",
    "        #time.sleep(2)\n",
    "        #best_loss = np.Inf\n",
    "        #search_iteration = 1\n",
    "        #\n",
    "        #gp_result = gp_minimize(func         = get_hyperopts,\n",
    "        #                        dimensions   = dimensions,\n",
    "        #                        acq_func     = 'EI', # Expected Improvement.\n",
    "        #                        n_calls      = 50,\n",
    "        #                        noise        = 0.01,\n",
    "        #                        n_jobs       = -1,\n",
    "        #                        kappa        = 5,\n",
    "        #                        x0           = default_parameters,\n",
    "        #                        random_state = SEED\n",
    "        #                       )\n",
    "        #\n",
    "        #\n",
    "        #print('\\nSEARCH COMPLETE.')\n",
    "        #print('MAKING VALIDATION PREDICTIONS...')\n",
    "        #\n",
    "        ## Load best model\n",
    "        #model = load_model(model_save_name)\n",
    "        ## Make validation predictions\n",
    "        #preds = model.predict(X_vdx_best_model)\n",
    "        #\n",
    "        ## Calculate OOF loss \n",
    "        #oof_loss = metric(np.array(y_vdx_best_model), np.array(preds))\n",
    "    #\n",
    "        #print('FOLD ' + str(fold) + ' LOSS: ' + str(oof_loss))\n",
    "        #print('--------------------------------------------------------------------------------------------')\n",
    "        #time.sleep(2)\n",
    "        #loss_scores.append(oof_loss)\n",
    "    #\n",
    "        ## Clean up\n",
    "        #gc.collect()\n",
    "        #os.remove(model_save_name_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b955f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a315d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005273d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db1c722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202913e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50b7ede6",
   "metadata": {},
   "source": [
    "### 3.07 Bayesian Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caada479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter search dimensions\n",
    "dim_learning_rate    = Real(low=1e-4,   high=1e-2, prior='log-uniform', name='learning_rate')\n",
    "dim_num_dense_layers = Integer(low=1,   high=6,    name='num_dense_layers')\n",
    "dim_num_input_nodes  = Integer(low=1,   high=4096, name='num_input_nodes')\n",
    "dim_num_dense_nodes  = Integer(low=1,   high=4096, name='num_dense_nodes')\n",
    "dim_activation = Categorical(categories=['relu','leaky_relu','elu','threshold_relu'], name='activation')\n",
    "dim_batch_size       = Integer(low=1,   high=64,   name='batch_size')\n",
    "dim_patience         = Integer(low=3,   high=15,   name='patience')\n",
    "dim_optimiser = Categorical(\n",
    "    categories=['sgd','adam','rms_prop','ada_delta','ada_grad', 'ada_max','n_adam','ftrl'], name='optimiser'\n",
    ")\n",
    "dim_optimiser_decay  = Real(low=1e-6,   high=1e-2, name='optimiser_decay')\n",
    "dim_dropout_layer = Categorical(categories=['dropout','gaussian_dropout','alpha_dropout'],name='dropout_layer')\n",
    "dim_dropout_val      = Real(low=0.1,    high=0.8,  name='dropout_val')\n",
    "\n",
    "dimensions = [\n",
    "    dim_learning_rate,\n",
    "    dim_num_dense_layers,\n",
    "    dim_num_input_nodes,\n",
    "    dim_num_dense_nodes,\n",
    "    dim_activation,\n",
    "    dim_batch_size,\n",
    "    dim_patience,\n",
    "    dim_optimiser,\n",
    "    dim_optimiser_decay,\n",
    "    dim_dropout_layer,\n",
    "    dim_dropout_val,\n",
    "]\n",
    "\n",
    "# Set default hyperparameters\n",
    "default_parameters = [\n",
    "    1e-3,      # learning_rate\n",
    "    1,         # num_dense_layers\n",
    "    512,       # num_input_nodes\n",
    "    16,        # num_dense_nodes\n",
    "    'relu',    # activation\n",
    "    64,        # batch_size\n",
    "    3,         # patience\n",
    "    'adam',    # optimiser\n",
    "    1e-3,      # optimiser_decay\n",
    "    'dropout', # dropout_layer\n",
    "    0.1,       # dropout_val\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d693fc97",
   "metadata": {},
   "source": [
    "### 3.08 Train Model with Bayesian Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5529d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CV strategy\n",
    "kf = KFold(n_splits=KFOLDS, random_state=SEED)\n",
    "loss_scores = []\n",
    "best_params = pd.DataFrame(columns=['kfold','selected_features','num_features',\n",
    "                                    'num_components','use_embedding','seed'])\n",
    "\n",
    "for fold, (tdx, vdx) in enumerate(kf.split(X, y)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------------------------------------------------------------------------')\n",
    "    # Create name to save model by\n",
    "    model_save_name = 'models/' + model_name_save + '/' + model_name_save + '_' + str(fold) + '.h5'\n",
    "    model_save_name_temp = 'models/' + model_name_save + '/' + 'TEMP_'+ model_name_save+ '_' + str(fold) + '.h5'\n",
    "    \n",
    "    @use_named_args(dimensions=dimensions)\n",
    "    def get_hyperopts(learning_rate, \n",
    "                      num_dense_layers, \n",
    "                      num_input_nodes, \n",
    "                      num_dense_nodes,\n",
    "                      activation, \n",
    "                      batch_size,\n",
    "                      patience,\n",
    "                      optimiser,\n",
    "                      optimiser_decay,\n",
    "                      dropout_layer,\n",
    "                      dropout_val):\n",
    "\n",
    "        # Define key parameters - these are affected by parameter search so must be done inside function\n",
    "        BATCH_SIZE = batch_size\n",
    "        PATIENCE   = patience\n",
    "\n",
    "        \n",
    "        # Fetch in-fold data\n",
    "        X_tdx, X_vdx, y_tdx, y_vdx = X.iloc[tdx, :], X.iloc[vdx, :], y.iloc[tdx, :], y.iloc[vdx, :]\n",
    "\n",
    "        # Define activation layers\n",
    "        if activation == 'relu':\n",
    "            ACTIVATION = ReLU()\n",
    "        elif activation == 'leaky_relu':\n",
    "            ACTIVATION = LeakyReLU()\n",
    "        elif activation == 'elu':\n",
    "            ACTIVATION = ELU()\n",
    "        elif activation == 'threshold_relu':\n",
    "            ACTIVATION = ThresholdedReLU()\n",
    "\n",
    "        # Define regularisation layers\n",
    "        if dropout_layer == 'dropout':\n",
    "            REG_LAYER = Dropout(dropout_val)\n",
    "        elif dropout_layer == 'gaussian_dropout':\n",
    "            REG_LAYER = GaussianDropout(dropout_val)\n",
    "        elif dropout_layer == 'alpha_dropout':\n",
    "            REG_LAYER = AlphaDropout(dropout_val)\n",
    "\n",
    "        # Define optimisers #\n",
    "        if optimiser == 'sgd':\n",
    "            OPTIMISER = SGD(lr=learning_rate, decay=optimiser_decay)\n",
    "        elif optimiser == 'adam':\n",
    "            OPTIMISER = RMSprop(lr=learning_rate, decay=optimiser_decay)\n",
    "        elif optimiser == 'rms_prop':\n",
    "            OPTIMISER = Adam(lr=learning_rate, decay=optimiser_decay)\n",
    "        elif optimiser == 'ada_delta':\n",
    "            OPTIMISER = Adadelta(lr=learning_rate, decay=optimiser_decay)\n",
    "        elif optimiser == 'ada_grad':\n",
    "            OPTIMISER = Adagrad(lr=learning_rate, decay=optimiser_decay)\n",
    "        elif optimiser == 'ada_max':\n",
    "            OPTIMISER = Adamax(lr=learning_rate, decay=optimiser_decay)\n",
    "        elif optimiser == 'n_adam':\n",
    "            OPTIMISER = Nadam(lr=learning_rate, decay=optimiser_decay)\n",
    "        elif optimiser == 'ftrl':\n",
    "            OPTIMISER = Ftrl(lr=learning_rate, decay=optimiser_decay)\n",
    "\n",
    "        ## BUILD MODEL BASED ON INPUTTED BAYESIAN HYPERPARAMETERS ##\n",
    "        # Input layer #\n",
    "        if USE_EMBEDDING == 1:\n",
    "            inputs = []\n",
    "            embeddings = []\n",
    "            for col in cat_cols:\n",
    "                # Create categorical embedding for each categorical feature\n",
    "                input_ = Input(shape=(1,))\n",
    "                input_dim = int(X_tdx[col].max() + 1)\n",
    "                embedding = Embedding(input_dim=input_dim, output_dim=10, input_length=1)(input_)\n",
    "                embedding = Reshape(target_shape=(10,))(embedding)\n",
    "                inputs.append(input_)\n",
    "                embeddings.append(embedding)\n",
    "            input_numeric = Input(shape=(len(num_cols),))\n",
    "            embedding_numeric = Dense(num_input_nodes)(input_numeric) \n",
    "            embedding_numeric = ACTIVATION(embedding_numeric) \n",
    "            inputs.append(input_numeric)\n",
    "            embeddings.append(embedding_numeric)\n",
    "            x = Concatenate()(embeddings)\n",
    "        if USE_EMBEDDING == 0:\n",
    "            input_ = Input(shape=(X_tdx.shape[1], ))\n",
    "            x = Dense(num_input_nodes)(input_)\n",
    "        # Hidden layers #\n",
    "        for i in range(num_dense_layers):\n",
    "            layer_name = f'layer_dense_{i+1}'\n",
    "            x = Dense(num_dense_nodes, name=layer_name)(x)\n",
    "            x = ACTIVATION(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = REG_LAYER(x) \n",
    "        # Output layer #\n",
    "        output = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "        if USE_EMBEDDING == 1:\n",
    "            model = Model(inputs, output)\n",
    "        elif USE_EMBEDDING == 0:\n",
    "            model = Model(input_, output)\n",
    "\n",
    "        \n",
    "        # COMPILE MODEL #\n",
    "        model.compile(optimizer=OPTIMISER, \n",
    "                      loss='binary_crossentropy')\n",
    "\n",
    "        # Define learning rate schedule\n",
    "        lr = LearningRateScheduler(lrfn, verbose=0)\n",
    "        \n",
    "        # Define early stopping parameters\n",
    "        es = EarlyStopping(monitor='val_loss', \n",
    "                           mode='min',\n",
    "                           restore_best_weights=True, \n",
    "                           verbose=0, \n",
    "                           patience=PATIENCE)\n",
    "        \n",
    "        # Define model checkpoint parameters\n",
    "        mc = ModelCheckpoint(filepath=model_save_name_temp, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False,\n",
    "                             monitor='val_loss', \n",
    "                             mode='min',\n",
    "                             verbose=0)\n",
    "\n",
    "        if USE_EMBEDDING == 1:\n",
    "            # Separate data to fit into embedding and numerical input layers\n",
    "            X_tdx = [np.absolute(X_tdx[i]) for i in cat_cols] + [X_tdx[num_cols]]\n",
    "            X_vdx = [np.absolute(X_vdx[i]) for i in cat_cols] + [X_vdx[num_cols]]\n",
    "\n",
    "        # FIT MODEL #\n",
    "        print('TRAINING...')\n",
    "        history = model.fit(X_tdx, y_tdx,\n",
    "                            epochs=EPOCHS,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            callbacks = [es, lr, mc],\n",
    "                            verbose=0,\n",
    "                            validation_split=0.25\n",
    "                           )\n",
    "        \n",
    "        # Get val_loss for the best model (one saved with ModelCheckpoint)\n",
    "        loss = min(history.history['val_loss'])\n",
    "        print(f'CURRENT LOSS: \\t\\t{loss}')\n",
    "        \n",
    "        # Save best loss and parameters to global memory\n",
    "        global best_loss\n",
    "        global best_params\n",
    "\n",
    "        # If the classification loss of the saved model is improved\n",
    "        if loss < best_loss:\n",
    "            model.save(model_save_name)\n",
    "            best_loss = loss\n",
    "            \n",
    "            # Save transformed validation arrays (so they can be used for prediction)\n",
    "            global X_vdx_best_model, y_vdx_best_model\n",
    "            X_vdx_best_model, y_vdx_best_model = X_vdx, y_vdx\n",
    "            \n",
    "            ### SAVE MODEL PARAMETERS ### \n",
    "            best_params = best_params.loc[best_params.kfold != fold]\n",
    "            best_params = best_params.append({'kfold'            : fold,\n",
    "                                              'selected_features': selected_features,\n",
    "                                              'num_features'     : NUM_FEATURES,\n",
    "                                              'num_components'   : NUM_COMPONENTS,\n",
    "                                              'use_embedding'    : USE_EMBEDDING,\n",
    "                                              'seed'             : SEED}, \n",
    "                                             ignore_index=True)\n",
    "            best_params.to_csv('final_classifier_parameters/' + model_name_save + '.csv', index=False)\n",
    "            \n",
    "        print(f'BEST LOSS: \\t\\t{best_loss}\\n')\n",
    "\n",
    "        del model\n",
    "        k.clear_session()\n",
    "        return(loss)\n",
    "    \n",
    "    ## RUN BAYESIAN HYPERPARAMETER SEARCH ##\n",
    "    print('RUNNING PARAMETER SEARCH...\\n')\n",
    "    time.sleep(2)\n",
    "    best_loss = np.Inf\n",
    "    search_iteration = 1\n",
    "    \n",
    "    gp_result = gp_minimize(func         = get_hyperopts,\n",
    "                            dimensions   = dimensions,\n",
    "                            acq_func     = 'EI', # Expected Improvement.\n",
    "                            n_calls      = 50,\n",
    "                            noise        = 0.01,\n",
    "                            n_jobs       = -1,\n",
    "                            kappa        = 5,\n",
    "                            x0           = default_parameters,\n",
    "                            random_state = SEED\n",
    "                           )\n",
    "    \n",
    "    \n",
    "    print('\\nSEARCH COMPLETE.')\n",
    "    print('MAKING VALIDATION PREDICTIONS...')\n",
    "    \n",
    "    # Load best model\n",
    "    model = load_model(model_save_name)\n",
    "    # Make validation predictions\n",
    "    preds = model.predict(X_vdx_best_model)\n",
    "    \n",
    "    # Calculate OOF loss \n",
    "    oof_loss = metric(np.array(y_vdx_best_model), np.array(preds))\n",
    "\n",
    "    print('FOLD ' + str(fold) + ' LOSS: ' + str(oof_loss))\n",
    "    print('--------------------------------------------------------------------------------------------------')\n",
    "    time.sleep(2)\n",
    "    loss_scores.append(oof_loss)\n",
    "\n",
    "    # Clean up\n",
    "    gc.collect()\n",
    "    os.remove(model_save_name_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cba3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a9888f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064fdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c13c571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
